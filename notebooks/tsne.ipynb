{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphcpp.dataset import CPPDataset\n",
    "\n",
    "train = CPPDataset(root='dataset', _split='train')\n",
    "val = CPPDataset(root='dataset', _split='val')\n",
    "test = CPPDataset(root='dataset', _split='test')\n",
    "dataset = list()\n",
    "for data in train: dataset.append(data)\n",
    "for data in val: dataset.append(data)\n",
    "for data in test: dataset.append(data)\n",
    "labels = [data.y.numpy()[0] for data in dataset]\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pooling or aggregating node features\n",
    "def mean_pooling(graph):\n",
    "    return torch.mean(graph.x, dim=0)\n",
    "def add_pooling(graph):\n",
    "    return torch.add(graph.x, dim=0)\n",
    "\n",
    "# Global Attention Pooling\n",
    "class GraphGlobalAttention(nn.Module):\n",
    "    def __init__(self, node_feature_dim, attention_dim):\n",
    "        super(GraphGlobalAttention, self).__init__()\n",
    "        self.attention = gnn.aggr.AttentionalAggregation(gate_nn=nn.Linear(node_feature_dim, 1), nn=nn.Linear(node_feature_dim, attention_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Graph should be a torch_geometric.data.Data object\n",
    "        return self.attention(x)\n",
    "\n",
    "global_attention_model = GraphGlobalAttention(node_feature_dim=32, attention_dim=256)\n",
    "\n",
    "graph_representations = []\n",
    "\n",
    "for graph in dataset:\n",
    "    pooled_features = mean_pooling(graph)\n",
    "    # pooled_features = global_attention_model(graph.x).squeeze(0)\n",
    "    graph_representations.append(pooled_features)\n",
    "\n",
    "# 2. Stack the graph representations\n",
    "graph_representations = torch.stack(graph_representations)\n",
    "\n",
    "# 3. Apply t-SNE\n",
    "tsne = TSNE(n_components=2,\n",
    "    perplexity=50,\n",
    "    # init=\"pca\",\n",
    "    # n_iter=10000,\n",
    "    random_state=42)\n",
    "embedded_graphs = tsne.fit_transform(graph_representations.detach().numpy())\n",
    "\n",
    "# Visualize the t-SNE results\n",
    "sns.scatterplot(x=embedded_graphs[:, 0], y=embedded_graphs[:, 1], hue=labels, alpha=0.8, palette=['#4c72b0', '#dd8452'], data=embedded_graphs)#.set(title=\"t-SNE projection of the entire dataset\") \n",
    "plt.savefig('assets/before_tsne.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('assets/before_tsne.eps', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('assets/before_tsne.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from graphcpp.fp_generators import fp_dict\n",
    "from graphcpp.lightning import GraphCPPModule\n",
    "\n",
    "# Before applying t-SNE, we should change the import in the lightning.py file.\n",
    "model = GraphCPPModule.load_from_checkpoint(checkpoint_path=\"model/checkpoints/epoch=50-step=1173.ckpt\").model\n",
    "model.eval()\n",
    "\n",
    "embeddings = list()\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        # Load fingerprint\n",
    "        mol = Chem.MolFromSmiles(data.smiles[0])\n",
    "        fp = fp_dict['topological'].GetFingerprint(mol)\n",
    "        data.fp = torch.tensor([fp], dtype=torch.float32)\n",
    "\n",
    "        pred, label, embedding = model(data)\n",
    "        embeddings.append(embedding.squeeze(0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_embedding = model_value[2].squeeze(0).numpy()\n",
    "X = np.array(embeddings)\n",
    "\n",
    "tsne = TSNE(n_components=2,\n",
    "    perplexity=50,\n",
    "    # init=\"pca\",\n",
    "    # n_iter=10000,\n",
    "    random_state=42)\n",
    "embedded_graphs = tsne.fit_transform(X)\n",
    "\n",
    "sns.scatterplot(x=embedded_graphs[:, 0], y=embedded_graphs[:, 1], hue=labels, alpha=0.8, palette=['#4c72b0', '#dd8452'], data=embedded_graphs)#.set(title=\"t-SNE projection of the entire dataset after training\") \n",
    "plt.savefig('assets/after_tsne.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('assets/after_tsne.eps', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('assets/after_tsne.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
